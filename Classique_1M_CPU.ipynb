{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eb3f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è Device utilis√© : cpu\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 0. IMPORTS & CONFIGURATION DE BASE\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from torch.optim import AdamW \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "# V√©rification du mat√©riel\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device utilis√© :\", device)\n",
    "\n",
    "# Pour la reproductibilit√©\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fced8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Nombre total de lignes : 159571\n",
      "üîñ Colonnes : ['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
      "üí¨ Exemple de texte : Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove th ...\n",
      "üßæ Distribution des labels :\n",
      "toxic            15294\n",
      "severe_toxic      1595\n",
      "obscene           8449\n",
      "threat             478\n",
      "insult            7877\n",
      "identity_hate     1405\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1. CHARGEMENT ET PR√âPARATION DU DATASET\n",
    "# ============================================================\n",
    "\n",
    "# Chemin vers ton CSV\n",
    "path = \"train.csv\"  \n",
    "\n",
    "df = pd.read_csv('../../jigsaw-toxic-comment-classification-challenge/train.csv/train.csv', encoding='UTF-8', on_bad_lines='skip')\n",
    "\n",
    "# Colonnes de labels\n",
    "label_cols = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "\n",
    "print(\"Nombre total de lignes :\", len(df))\n",
    "print(\"Colonnes :\", list(df.columns))\n",
    "print(\"Exemple de texte :\", df['comment_text'][0][:200], \"...\")\n",
    "print(\"Distribution des labels :\")\n",
    "print(df[label_cols].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23774569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>d'aww! he matches this background colour i'm s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>hey man, i'm really not trying to edit war. it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>more i can't make any real suggestions on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>you, sir, are my hero. any chance you remember...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...   \n",
       "1  D'aww! He matches this background colour I'm s...   \n",
       "2  Hey man, I'm really not trying to edit war. It...   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4  You, sir, are my hero. Any chance you remember...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  explanation why the edits made under my userna...  \n",
       "1  d'aww! he matches this background colour i'm s...  \n",
       "2  hey man, i'm really not trying to edit war. it...  \n",
       "3  more i can't make any real suggestions on impr...  \n",
       "4  you, sir, are my hero. any chance you remember...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 2. NETTOYAGE DU TEXTE POUR TRANSFORMERS\n",
    "# ============================================================\n",
    "\n",
    "def clean_text_for_transformer(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Normaliser les apostrophes et guillemets\n",
    "    text = text.replace(\"‚Äô\", \"'\").replace(\"‚Äú\", '\"').replace(\"‚Äù\", '\"').replace(\"`\", \"'\")\n",
    "    \n",
    "    # Supprimer les URLs et adresses IP\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \" url \", text)\n",
    "    text = re.sub(r\"\\b\\d{1,3}(?:\\.\\d{1,3}){3}\\b\", \" \", text)\n",
    "    \n",
    "    # Transformer les √©mojis en texte\n",
    "    text = emoji.demojize(text)\n",
    "    \n",
    "    # Garder ponctuation de base (. , ? ! ')\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s\\.,!?']\", \" \", text)\n",
    "    \n",
    "    # Supprimer les multiples espaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    return text.lower()\n",
    "\n",
    "df[\"clean_text\"] = df[\"comment_text\"].apply(clean_text_for_transformer)\n",
    "df[[\"comment_text\", \"clean_text\"]].head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8ec281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du dataset r√©duit : 10000\n",
      "                                        comment_text  \\\n",
      "0  Geez, are you forgetful!  We've already discus...   \n",
      "1  Carioca RFA \\n\\nThanks for your support on my ...   \n",
      "\n",
      "                                          clean_text  \n",
      "0  geez, are you forgetful! we've already discuss...  \n",
      "1  carioca rfa thanks for your support on my requ...  \n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# OPTION DEV RAPIDE : √âCHANTILLONNAGE DU DATASET\n",
    "# ============================================================\n",
    "\n",
    "# Cr√©ation d'un sous-√©chantillon pour acc√©l√©rer l'entra√Ænement sur CPU\n",
    "df_sample = df.sample(10000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"Taille du dataset r√©duit :\", len(df_sample))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc42f8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du train set : 9000\n",
      "Taille du validation set : 1000\n",
      "Tokenisation et Dataset pr√™ts !\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 3. TOKENISATION ET CR√âATION DU DATASET PYTORCH\n",
    "# ============================================================\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Choix du mod√®le principal\n",
    "model_name = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# S√©paration train / validation\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df_sample[\"clean_text\"].tolist(),\n",
    "    df_sample[[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]].values,\n",
    "    test_size=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Tokenisation\n",
    "train_encodings = tokenizer(\n",
    "    train_texts,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128\n",
    ")\n",
    "\n",
    "val_encodings = tokenizer(\n",
    "    val_texts,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128\n",
    ")\n",
    "\n",
    "# Classe Dataset pour PyTorch\n",
    "class ToxicCommentsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx]).float()\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = ToxicCommentsDataset(train_encodings, train_labels)\n",
    "val_dataset = ToxicCommentsDataset(val_encodings, val_labels)\n",
    "\n",
    "print(f\"Taille du train set : {len(train_dataset)}\")\n",
    "print(f\"Taille du validation set : {len(val_dataset)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b9d9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Epoch 1/2 - Loss moyenne : 0.0815\n",
      "üìâ Epoch 2/2 - Loss moyenne : 0.0440\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 4. ENTRA√éNEMENT DU MOD√àLE RoBERTa-base\n",
    "# ============================================================\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# Chargement du mod√®le RoBERTa\n",
    "model_name = \"roberta-base\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=6,  # 6 √©tiquettes dans Jigsaw\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Optimiseur et scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "num_epochs = 2  # CPU -> 2 epochs max\n",
    "num_training_steps = len(train_loader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "# Fonction d'entra√Ænement\n",
    "def train_model(model, loader, optimizer, scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Boucle d'entra√Ænement\n",
    "for epoch in range(num_epochs):\n",
    "    avg_loss = train_model(model, train_loader, optimizer, scheduler)\n",
    "    print(f\" Epoch {epoch+1}/{num_epochs} - Loss moyenne : {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4f129a",
   "metadata": {},
   "source": [
    "Le mod√®le RoBERTa-base a √©t√© initialis√© avec des poids pr√©-entra√Æn√©s,\n",
    "la t√™te de classification a √©t√© ajout√©e et entra√Æn√©e √† partir de z√©ro sur notre dataset Jigsaw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1a76573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " F1-score macro sur le set de validation : 0.4661\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 5. √âVALUATION DU MOD√àLE RoBERTa-base\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "preds, truths = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        probs = torch.sigmoid(outputs.logits).cpu().numpy()\n",
    "        preds.extend(probs)\n",
    "        truths.extend(batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "preds = np.array(preds)\n",
    "truths = np.array(truths)\n",
    "\n",
    "# Transformation en 0/1 (seuil 0.5)\n",
    "preds_binary = (preds > 0.5).astype(int)\n",
    "\n",
    "# Calcul du F1-score macro\n",
    "f1 = f1_score(truths, preds_binary, average=\"macro\")\n",
    "print(f\" F1-score macro sur le set de validation : {f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
